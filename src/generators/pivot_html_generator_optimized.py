# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–ç‰ˆé«˜ä½ç‚¹HTMLç”Ÿæˆå™¨ - ä½¿ç”¨æ¨¡æ¿ç³»ç»Ÿç”ŸæˆæŠ¥å‘Š
å¤§å¹…å‡å°‘æ–‡ä»¶å¤§å°ï¼Œæé«˜å¯ç»´æŠ¤æ€§
"""

import os
import json
import numpy as np
from datetime import datetime
from src.generators.html_templates import StockAnalysisTemplate, ReportGenerator
from src.utils.logger import get_logger

logger = get_logger(__name__)


class PivotHTMLGeneratorOptimized:
    """ä¼˜åŒ–ç‰ˆé«˜ä½ç‚¹HTMLæŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir="output/pivot"):
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(os.path.join(output_dir, '..', 'assets'), exist_ok=True)
        
        self.template = StockAnalysisTemplate()
        self.report_generator = ReportGenerator(self.template)
        
    def generate_pivot_html(self, pivot_results, chart_paths, stock_names=None):
        """ç”Ÿæˆé«˜ä½ç‚¹åˆ†æHTMLé¡µé¢"""
        if not pivot_results:
            logger.error("æ²¡æœ‰é«˜ä½ç‚¹åˆ†æç»“æœï¼Œæ— æ³•ç”ŸæˆHTML")
            return None
        
        logger.info(f"å¼€å§‹ç”Ÿæˆé«˜ä½ç‚¹åˆ†æHTMLï¼Œå…± {len(pivot_results)} åªè‚¡ç¥¨")
        
        # æŒ‰ç…§å¤§å¼§åº•JSONæ–‡ä»¶çš„é¡ºåºæ’åº
        sorted_codes = self._sort_by_arc_order(pivot_results)
        
        # å‡†å¤‡ç»Ÿè®¡æ•°æ®
        stats = self._calculate_stats(pivot_results)
        
        # å‡†å¤‡æ•°æ®é¡¹
        items = []
        for code in sorted_codes:
            if code not in chart_paths:
                continue
                
            items.append({
                'code': code,
                'name': stock_names.get(code, code) if stock_names else code,
                'result': pivot_results[code],
                'paths': chart_paths[code]
            })
        
        # ç”ŸæˆæŠ¥å‘Š
        html_content = self.report_generator.generate_paginated_report(
            title="é«˜ä½ç‚¹åˆ†ææŠ¥å‘Š",
            subtitle=f"åŸºäºZigZag+ATRç®—æ³•çš„å…³é”®è½¬æŠ˜ç‚¹è¯†åˆ« Â· {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}",
            stats=stats,
            items=items,
            items_per_page=5,
            item_renderer=self._render_stock_item
        )
        
        # ä¿å­˜HTMLæ–‡ä»¶
        html_path = os.path.join(self.output_dir, "index.html")
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        # ä¿å­˜åˆ†æç»“æœJSON
        self._save_analysis_json(sorted_codes, pivot_results)
        
        logger.info(f"é«˜ä½ç‚¹åˆ†æHTMLå·²ç”Ÿæˆ: {html_path}")
        logger.info(f"æ–‡ä»¶å¤§å°: {os.path.getsize(html_path) / 1024 / 1024:.2f} MB")
        
        return html_path
    
    def _sort_by_arc_order(self, pivot_results):
        """æŒ‰ç…§ä¼˜è´¨è‚¡ç¥¨ä¼˜å…ˆï¼Œç„¶åæŒ‰å¤§å¼§åº•JSONæ–‡ä»¶çš„é¡ºåºæ’åº"""
        arc_json_path = "output/arc/top_100.json"
        
        try:
            with open(arc_json_path, 'r', encoding='utf-8') as f:
                arc_order = json.load(f)
            
            logger.info(f"ä» {arc_json_path} åŠ è½½äº† {len(arc_order)} åªè‚¡ç¥¨çš„æ’åº")
            
            # åˆ†ç¦»ä¼˜è´¨å’Œæ™®é€šè‚¡ç¥¨
            premium_codes = []
            normal_codes = []
            
            # é¦–å…ˆæŒ‰ç…§JSONé¡ºåºå¤„ç†åœ¨arc_orderä¸­çš„è‚¡ç¥¨
            for code in arc_order:
                if code in pivot_results:
                    premium_metrics = pivot_results[code].get('premium_metrics', {})
                    is_premium = premium_metrics.get('is_premium', False)
                    if is_premium:
                        premium_codes.append(code)
                    else:
                        normal_codes.append(code)
            
            # å¤„ç†ä¸åœ¨arc_orderä¸­çš„è‚¡ç¥¨
            remaining_premium = []
            remaining_normal = []
            for code in pivot_results:
                if code not in arc_order:
                    premium_metrics = pivot_results[code].get('premium_metrics', {})
                    is_premium = premium_metrics.get('is_premium', False)
                    if is_premium:
                        remaining_premium.append(code)
                    else:
                        remaining_normal.append(code)
            
            # æŒ‰å‡†ç¡®åº¦æ’åºå‰©ä½™è‚¡ç¥¨
            remaining_premium.sort(
                key=lambda x: pivot_results[x].get('accuracy_score', 0), 
                reverse=True
            )
            remaining_normal.sort(
                key=lambda x: pivot_results[x].get('accuracy_score', 0), 
                reverse=True
            )
            
            # åˆå¹¶ç»“æœï¼šä¼˜è´¨è‚¡ç¥¨åœ¨å‰ï¼Œæ™®é€šè‚¡ç¥¨åœ¨å
            sorted_codes = premium_codes + remaining_premium + normal_codes + remaining_normal
            
            # è®°å½•ä¼˜è´¨è‚¡ç¥¨æ•°é‡
            total_premium = len(premium_codes) + len(remaining_premium)
            logger.info(f"å…±æ‰¾åˆ° {total_premium} åªä¼˜è´¨è‚¡ç¥¨ï¼Œå·²æ’åœ¨å‰é¢")
            
            return sorted_codes
            
        except Exception as e:
            logger.warning(f"æ— æ³•åŠ è½½å¤§å¼§åº•æ’åºæ–‡ä»¶: {e}")
            # å¦‚æœæ— æ³•åŠ è½½ï¼Œåˆ™æŒ‰å‡†ç¡®åº¦å’Œç»¼åˆè¯„åˆ†æ’åº
            return self._sort_by_score(pivot_results)
    
    def _sort_by_score(self, pivot_results):
        """æŒ‰ä¼˜è´¨è‚¡ç¥¨ä¼˜å…ˆï¼Œç„¶åæŒ‰è¯„åˆ†æ’åºè‚¡ç¥¨ä»£ç """
        premium_scores = []
        normal_scores = []
        
        for code, result in pivot_results.items():
            accuracy_score = result.get('accuracy_score', 0)
            volatility = result.get('volatility_metrics', {}).get('weekly_volatility', 0)
            premium_metrics = result.get('premium_metrics', {})
            is_premium = premium_metrics.get('is_premium', False)
            
            # ç»¼åˆè¯„åˆ†ï¼ˆå‡†ç¡®åº¦å’Œæ³¢åŠ¨ç‡çš„å¹³è¡¡ï¼‰
            combined_score = accuracy_score * 0.7 + min(volatility * 2, 1.0) * 0.3
            
            if is_premium:
                premium_scores.append((code, combined_score))
            else:
                normal_scores.append((code, combined_score))
        
        # åˆ†åˆ«æŒ‰è¯„åˆ†é™åºæ’åº
        premium_scores.sort(key=lambda x: x[1], reverse=True)
        normal_scores.sort(key=lambda x: x[1], reverse=True)
        
        # ä¼˜è´¨è‚¡ç¥¨åœ¨å‰ï¼Œæ™®é€šè‚¡ç¥¨åœ¨å
        sorted_codes = [code for code, score in premium_scores] + [code for code, score in normal_scores]
        
        logger.info(f"æŒ‰è¯„åˆ†æ’åºï¼š{len(premium_scores)} åªä¼˜è´¨è‚¡ç¥¨æ’åœ¨å‰é¢")
        
        return sorted_codes
    
    def _calculate_stats(self, pivot_results):
        """è®¡ç®—ç»Ÿè®¡æ•°æ®"""
        total_stocks = len(pivot_results)
        
        # è®¡ç®—å¹³å‡å‡†ç¡®åº¦
        accuracy_scores = [
            result.get('accuracy_score', 0) 
            for result in pivot_results.values()
        ]
        avg_accuracy = np.mean(accuracy_scores) if accuracy_scores else 0
        
        # è®¡ç®—é«˜è´¨é‡è‚¡ç¥¨æ•°é‡
        high_quality = sum(1 for score in accuracy_scores if score >= 0.8)
        
        # è®¡ç®—å¹³å‡æ¢è½´ç‚¹æ•°é‡
        pivot_counts = []
        for result in pivot_results.values():
            filtered_highs = result.get('filtered_pivot_highs', [])
            filtered_lows = result.get('filtered_pivot_lows', [])
            pivot_counts.append(len(filtered_highs) + len(filtered_lows))
        avg_pivots = np.mean(pivot_counts) if pivot_counts else 0
        
        return [
            {'value': total_stocks, 'label': 'åˆ†æè‚¡ç¥¨æ€»æ•°'},
            {'value': f"{avg_accuracy:.1%}", 'label': 'å¹³å‡å‡†ç¡®åº¦'},
            {'value': high_quality, 'label': 'é«˜è´¨é‡ä¿¡å·'},
            {'value': f"{avg_pivots:.1f}", 'label': 'å¹³å‡æ¢è½´ç‚¹æ•°'}
        ]
    
    def _render_stock_item(self, item, index):
        """æ¸²æŸ“å•ä¸ªè‚¡ç¥¨é¡¹ç›®"""
        code = item['code']
        name = item['name']
        result = item['result']
        paths = item['paths']
        
        # è·å–æ˜¯å¦ä¼˜è´¨
        premium_metrics = result.get('premium_metrics', {})
        is_premium = premium_metrics.get('is_premium', False)
        
        # å‡†å¤‡å›¾ç‰‡è·¯å¾„
        images = {
            'original': os.path.relpath(paths['original'], self.output_dir),
            'pivot': os.path.relpath(paths['pivot'], self.output_dir)
        }
        
        # ç”Ÿæˆåˆ†æå†…å®¹
        analysis_html = self._generate_analysis_html(result)
        
        return self.template.get_stock_row(
            code=code,
            name=name,
            index=index,
            quality_class='quality-premium' if is_premium else 'quality-normal',
            quality_text='ğŸŒŸ ä¼˜è´¨' if is_premium else '',
            images=images,
            analysis_html=analysis_html
        )
    
    # åˆ é™¤ _get_quality_class æ–¹æ³•ï¼Œä¸å†éœ€è¦
    
    def _generate_analysis_html(self, result):
        """ç”Ÿæˆåˆ†æå†…å®¹HTML"""
        # æå–å…³é”®æŒ‡æ ‡
        accuracy_score = result.get('accuracy_score', 0)
        volatility_metrics = result.get('volatility_metrics', {})
        pivot_meta = result.get('pivot_meta', {})
        premium_metrics = result.get('premium_metrics', {})
        
        html = ""
        
        # 1. æŠ•èµ„è´¨é‡è¯„ä¼°ï¼ˆé‡ç‚¹å±•ç¤ºï¼‰
        quality_metrics = []
        
        # æ·»åŠ æœ€ä½ç‚¹ä¿¡æ¯
        if premium_metrics.get('t1'):
            quality_metrics.extend([
                {'label': 'æœ€ä½ç‚¹æ—¶é—´', 'value': premium_metrics.get('t1', '-')},
                {'label': 'æœ€ä½ç‚¹ä»·æ ¼', 'value': f"{premium_metrics.get('p1', 0):.2f}" if premium_metrics.get('p1') else '-'}
            ])
        
        quality_metrics.extend([
            {'label': 'å¹´åŒ–æ³¢åŠ¨ç‡', 'value': f"{premium_metrics.get('annualized_volatility_pct', 0):.1f}%"},
            {'label': 'å¤æ™®æ¯”ç‡', 'value': f"{premium_metrics.get('sharpe_ratio', 0):.2f}"},
            {'label': 'æ˜¯å¦ä¼˜è´¨', 'value': 'âœ… ä¼˜è´¨' if premium_metrics.get('is_premium', False) else 'âŒ æ™®é€š'}
        ])
        
        html += self.template.get_metric_group('æŠ•èµ„è´¨é‡', quality_metrics)
        
        # 2. äº¤æ˜“å»ºè®®
        html += self._generate_trading_suggestion(result)
        
        return html
    
    def _generate_trading_suggestion(self, result):
        """ç”Ÿæˆäº¤æ˜“å»ºè®®"""
        accuracy_score = result.get('accuracy_score', 0)
        premium_metrics = result.get('premium_metrics', {})
        is_premium = premium_metrics.get('is_premium', False)
        volatility = premium_metrics.get('annualized_volatility_pct', 0)
        
        suggestion = "<div class='metric-group'><h4>äº¤æ˜“å»ºè®®</h4><p style='line-height: 1.5; margin: 0;'>"
        
        # ç®€åŒ–å»ºè®®
        if is_premium:
            suggestion += "ğŸŒŸ <strong>ä¼˜è´¨</strong>ï¼šé£é™©æ”¶ç›Šæ¯”ä¼˜ç§€"
        elif volatility >= 40:
            suggestion += "ğŸ“Š <strong>é«˜æ³¢åŠ¨</strong>ï¼šéœ€è°¨æ…è¯„ä¼°é£é™©"
        else:
            suggestion += "ğŸ“ˆ <strong>ç¨³å¥</strong>ï¼šé€‚åˆç¨³å¥æŠ•èµ„"
        
        if accuracy_score >= 0.8:
            suggestion += " | âœ… ä¿¡å·å¯é "
        
        suggestion += "</p></div>"
        
        return suggestion
    
    def _save_analysis_json(self, sorted_codes, pivot_results):
        """ä¿å­˜åˆ†æç»“æœä¸ºJSONæ ¼å¼"""
        summary = {
            'generated_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_stocks': len(sorted_codes),
            'stocks': []
        }
        
        for code in sorted_codes:
            if code in pivot_results:
                result = pivot_results[code]
                summary['stocks'].append({
                    'code': code,
                    'accuracy_score': result.get('accuracy_score', 0),
                    'pivot_count': len(result.get('filtered_pivot_highs', [])) + 
                                  len(result.get('filtered_pivot_lows', [])),
                    'volatility': result.get('volatility_metrics', {}).get('weekly_volatility', 0)
                })
        
        json_path = os.path.join(self.output_dir, 'pivot_analysis_summary.json')
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        logger.info(f"åˆ†ææ‘˜è¦å·²ä¿å­˜åˆ°: {json_path}")
